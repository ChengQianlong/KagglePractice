import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.pipeline import Pipeline, make_pipeline
from scipy.stats import skew
from sklearn.linear_model import Lasso
from sklearn.preprocessing import Imputer
from sklearn.tree import DecisionTreeRegressor

warnings.filterwarnings('ignore')
pd.set_option('display.width', 1000)
pd.set_option('display.max_columns',1000)
pd.set_option('display.max_colwidth',1000)
plt.style.use('ggplot')

# 自己写一个转换函数
class labelenc(BaseEstimator, TransformerMixin):
    def __init__(self):
        pass
    def fit(self,X,y=None):
        return self
    def transform(self,X):
        lab=LabelEncoder()
        X["YearBuilt"] = lab.fit_transform(X["YearBuilt"])
        X["YearRemodAdd"] = lab.fit_transform(X["YearRemodAdd"])
        X["GarageYrBlt"] = lab.fit_transform(X["GarageYrBlt"])
        X["BldgType"] = lab.fit_transform(X["BldgType"])
        return X
class skew_dummies(BaseEstimator, TransformerMixin):
    def __init__(self, skew=0.5):
        self.skew = skew
    def fit(self,X,y=None):
        return self
    def transform(self,X):
        X_numeric=X.select_dtypes(exclude=['object'])
        skewness = X_numeric.apply(lambda x: skew(x))
        skewness_features = skewness[abs(skewness) > self.skew].index
        X[skewness_features] = np.log1p(X[skewness_features])
        X = pd.get_dummies(X)
        return X

class add_feature(BaseEstimator, TransformerMixin):  # 自己定义转换函数--fit_transform由自己定义
    def __init__(self, additional=1):
        self.additional = additional

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        if self.additional == 1:
            X["TotalHouse"] = X["TotalBsmtSF"] + X["1stFlrSF"] + X["2ndFlrSF"]
            X["TotalArea"] = X["TotalBsmtSF"] + X["1stFlrSF"] + X["2ndFlrSF"] + X["GarageArea"]

        else:
            X["TotalHouse"] = X["TotalBsmtSF"] + X["1stFlrSF"] + X["2ndFlrSF"]
            X["TotalArea"] = X["TotalBsmtSF"] + X["1stFlrSF"] + X["2ndFlrSF"] + X["GarageArea"]

            X["+_TotalHouse_OverallQual"] = X["TotalHouse"] * X["OverallQual"]
            X["+_GrLivArea_OverallQual"] = X["GrLivArea"] * X["OverallQual"]
            X["+_oMSZoning_TotalHouse"] = X["MSZoning"] * X["TotalHouse"]
            X["+_oMSZoning_OverallQual"] = X["MSZoning"] + X["OverallQual"]
            X["+_oMSZoning_YearBuilt"] = X["MSZoning"] + X["YearBuilt"]
            X["+_oNeighborhood_TotalHouse"] = X["Neighborhood"] * X["TotalHouse"]
            X["+_oNeighborhood_OverallQual"] = X["Neighborhood"] + X["OverallQual"]
            X["+_oNeighborhood_YearBuilt"] = X["Neighborhood"] + X["YearBuilt"]
            X["+_BsmtFinSF1_OverallQual"] = X["BsmtFinSF1"] * X["OverallQual"]

            X["-_oFunctional_TotalHouse"] = X["Functional"] * X["TotalHouse"]
            X["-_oFunctional_OverallQual"] = X["Functional"] + X["OverallQual"]
            X["-_LotArea_OverallQual"] = X["LotArea"] * X["OverallQual"]
            X["-_TotalHouse_LotArea"] = X["TotalHouse"] + X["LotArea"]
            X["-_oCondition1_TotalHouse"] = X["Condition1"] * X["TotalHouse"]
            X["-_oCondition1_OverallQual"] = X["Condition1"] + X["OverallQual"]

            X["Bsmt"] = X["BsmtFinSF1"] + X["BsmtFinSF2"] + X["BsmtUnfSF"]
            X["Rooms"] = X["FullBath"] + X["TotRmsAbvGrd"]
            X["PorchArea"] = X["OpenPorchSF"] + X["EnclosedPorch"] + X["3SsnPorch"] + X["ScreenPorch"]
            X["TotalPlace"] = X["TotalBsmtSF"] + X["1stFlrSF"] + X["2ndFlrSF"] + X["GarageArea"] + X["OpenPorchSF"] + X[
                "EnclosedPorch"] + X["3SsnPorch"] + X["ScreenPorch"]

        return X



# 数据预览
train = pd.read_csv('./data/train.csv')
test = pd.read_csv('./data/test.csv')
# print(train.columns.values.tolist())
# print(train.shape)
# print(train.head(2))
# print(test.head(2))
# plt.figure(figsize=(10,8))
# sns.boxplot(train.YearBuilt, train.SalePrice)
# plt.show()
# plt.figure(figsize=(12,6))
# plt.scatter(x=train.GrLivArea, y=train.SalePrice)
# plt.xlabel("GrLivArea", fontsize = 13)
# plt.ylabel("SalePrice", fontsize = 13)
# plt.ylim(0, 800000)
# plt.show()
train.drop(train[(train['GrLivArea'] > 4000) & (train['SalePrice']<300000)].index, inplace=True)
full = pd.concat([train, test], ignore_index=True)
full.drop('Id', axis=1,inplace = True)
# print(full.columns.values.tolist())
print(full.shape)
# print(full.info())

# 数据清洗：空值填充、空值删除、不处理
miss = full.isnull().sum()
# print(miss[miss>0].sort_values(ascending=True))
cols1 = ["PoolQC" , "MiscFeature", "Alley", "Fence", "FireplaceQu", "GarageQual", "GarageCond", "GarageFinish", "GarageYrBlt", "GarageType", "BsmtExposure", "BsmtCond", "BsmtQual", "BsmtFinType2", "BsmtFinType1", "MasVnrType"]
for col in cols1:
    full[col].fillna("None",inplace=True)
cols=["MasVnrArea", "BsmtUnfSF", "TotalBsmtSF", "GarageCars", "BsmtFinSF2", "BsmtFinSF1", "GarageArea"]
for col in cols:
    full[col].fillna(0, inplace=True)
full['LotFrontage'].fillna(np.mean(full['LotFrontage']),inplace=True)
cols2 = ["MSZoning", "BsmtFullBath", "BsmtHalfBath", "Utilities", "Functional", "Electrical", "KitchenQual", "SaleType","Exterior1st", "Exterior2nd"]
for col in cols2:
    full[col].fillna(full[col].mode()[0],inplace=True)
# print(np.mean(full['LotFrontage']))
# print(full['MSZoning'].mode()[0])
# print(full.isnull().sum()[full.isnull().sum()>0])

# 数据预处理：字符变成数值型，这一步很重要
# 将一些数字特征转换为类别特征。最好使用LabelEncoder和get_dummies来实现这些功能。
for col in cols2:
    full[col]=full[col].astype(str)
lab = LabelEncoder()
full['Alley'] = lab.fit_transform(full.Alley)
full['PoolQC'] = lab.fit_transform(full.PoolQC)
full["MiscFeature"] = lab.fit_transform(full.MiscFeature)
full["Fence"] = lab.fit_transform(full.Fence)
full["FireplaceQu"] = lab.fit_transform(full.FireplaceQu)
full["GarageQual"] = lab.fit_transform(full.GarageQual)
full["GarageCond"] = lab.fit_transform(full.GarageCond)
full["GarageFinish"] = lab.fit_transform(full.GarageFinish)
full["GarageYrBlt"] = full["GarageYrBlt"].astype(str)
full["GarageYrBlt"] = lab.fit_transform(full.GarageYrBlt)
full["GarageType"] = lab.fit_transform(full.GarageType)
full["BsmtExposure"] = lab.fit_transform(full.BsmtExposure)
full["BsmtCond"] = lab.fit_transform(full.BsmtCond)
full["BsmtQual"] = lab.fit_transform(full.BsmtQual)
full["BsmtFinType2"] = lab.fit_transform(full.BsmtFinType2)
full["BsmtFinType1"] = lab.fit_transform(full.BsmtFinType1)
full["MasVnrType"] = lab.fit_transform(full.MasVnrType)
full["BsmtFinType1"] = lab.fit_transform(full.BsmtFinType1)
full["MSZoning"] = lab.fit_transform(full.MSZoning)
full["BsmtFullBath"] = lab.fit_transform(full.BsmtFullBath)
full["BsmtHalfBath"] = lab.fit_transform(full.BsmtHalfBath)
full["Utilities"] = lab.fit_transform(full.Utilities)
full["Functional"] = lab.fit_transform(full.Functional)
full["Electrical"] = lab.fit_transform(full.Electrical)
full["KitchenQual"] = lab.fit_transform(full.KitchenQual)
full["SaleType"] = lab.fit_transform(full.SaleType)
full["Exterior1st"] = lab.fit_transform(full.Exterior1st)
full["Exterior2nd"] = lab.fit_transform(full.Exterior2nd)


full.drop('SalePrice', axis=1, inplace=True)
# print(full.head())
# print(full.shape)

# 继续数据处理，只是自己编写了函数，用管道的方式处理

pipe = Pipeline([
    ('labenc', labelenc()),
    ('add_feature', add_feature(additional=1)),
    ('skew_dummies', skew_dummies(skew=4))
])
full2 = full.copy()
pipeline_data = pipe.fit_transform(full2)
print(pipeline_data.shape)
print(pipeline_data.head())

# 抽取出训练集和测试集
n_train = train.shape[0]
X = pipeline_data[:n_train]
test_X = pipeline_data[n_train:]
y=train.SalePrice
X_scaled = StandardScaler().fit(X).transform(X)
y_log = np.log(train.SalePrice)
test_X_scaled = StandardScaler().fit_transform(test_X)

# 特征选择
# lasso = Lasso(alpha=0.001)
# lasso.fit(X_scaled,y_log)
# FI_lasso = pd.DataFrame({'Feature Importance':lasso.coef_}, index=pipeline_data.columns)
# pr = FI_lasso.sort_values('Feature Importance',ascending=False)
# # print(pr)
# # FI_lasso[FI_lasso['Feature Importance']!=0].sort_values("Feature Importance").plot(kind='barh',figsize=(15,25))
# # plt.xticks(rotation=90)
# # plt.show()
#
#
# print(pipe)

# 模型训练以及预测的一个简单测试
# model = DecisionTreeRegressor()
# model1 = model.fit(X_scaled,y_log)
# predict = np.exp(model1.predict(test_X_scaled))
# result = pd.DataFrame({"Id":test.Id, "SalePrice":predict})
# result.to_csv("submission1.csv",index=False)

'''
模型集成stacking、调参、模型评估
'''
from sklearn.model_selection import cross_val_score, GridSearchCV, KFold
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.svm import SVR,LinearSVR
from sklearn.linear_model import ElasticNet, SGDRegressor,BayesianRidge
from sklearn.kernel_ridge import KernelRidge
from xgboost import XGBRegressor

# 定义交叉验证及评估函数
def rmse_cv(model, X, y):
    rmse = np.sqrt(-cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5))
    return rmse

models = [LinearRegression(), Ridge(),Lasso(alpha=0.01,max_iter=10000),RandomForestRegressor(),GradientBoostingRegressor(),
          SVR(),LinearSVR(),ElasticNet(alpha=0.001,max_iter=10000),SGDRegressor(max_iter=1000,tol=1e-3),BayesianRidge(),
          KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),ExtraTreesRegressor(),XGBRegressor()
          ]
names = ['LR','Ridge','Lasso','RF','GBR','SVR','LinSVR','Ela','SGD','Bay','Ker','Extra','Xgb']
for name,model in zip(names,models):
    score = rmse_cv(model, X_scaled,y_log)
    print("{}: {:.6f} {:.4f}".format(name,score.mean(),score.std()))

class grid():
    def __init__(self,model):
        self.model = model
    def grid_get(self,X,y,param_grid):
        grid_search = GridSearchCV(self.model,param_grid,cv=5,scoring='neg_mean_squared_error')
        grid_search.fit(X,y)
        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))
        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])
        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])

grid(Lasso()).grid_get(X_scaled, y_log, {'alpha':[0.0004,0.0005,0.0007,0.0006,0.0009,0.0008], 'max_iter':[10000]})
grid(Ridge()).grid_get(X_scaled,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})
grid(SVR()).grid_get(X_scaled,y_log,{'C':[11,12,13,14,15],'kernel':["rbf"],"gamma":[0.0003,0.0004],"epsilon":[0.008,0.009]})
param_grid = {'alpha':[0.2,0.3,0.4,0.5], 'kernel':["polynomial"], 'degree':[3],'coef0':[0.8,1,1.2]}
grid(KernelRidge()).grid_get(X_scaled,y_log,param_grid)
grid(ElasticNet()).grid_get(X_scaled,y_log,{'alpha':[0.0005,0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3,0.5,0.7],'max_iter':[10000]})


##定义加权平均值，就相当于自己写fit_transform（）
class AverageWeight(BaseEstimator, RegressorMixin):
    def __init__(self, mod, weight):
        self.mod = mod  ##模型的个数
        self.weight = weight  ##权重

    def fit(self, X, y):
        self.models_ = [clone(x) for x in self.mod]
        for model in self.models_:
            model.fit(X, y)
        return self

    def predict(self, X):
        w = list()
        pred = np.array([model.predict(X) for model in self.models_])
        # 针对于每一个数据点，单一的模型是乘以权重，然后加起来
        for data in range(pred.shape[1]):
            single = [pred[model, data] * weight for model, weight in zip(range(pred.shape[0]), self.weight)]
            w.append(np.sum(single))
        return w

# 对这些基础模型的参数必须理解透以及掌握调参技巧
# 对这些基础模型的参数必须理解透以及掌握调参技巧
lasso = Lasso(alpha=0.0005,max_iter=10000)
ridge = Ridge(alpha=60)
svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)
ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)
ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)
bay = BayesianRidge()

##6个权重
w1 = 0.02
w2 = 0.2
w3 = 0.25
w4 = 0.3
w5 = 0.03
w6 = 0.2

weight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])
rmse_result = rmse_cv(weight_avg,X_scaled,y_log)
rmse_mean = rmse_cv(weight_avg,X_scaled,y_log).mean()
print(rmse_result)
print(rmse_mean)


'''
 模型的堆叠
 stacking
'''


class stacking(BaseEstimator, RegressorMixin, TransformerMixin):
    def __init__(self, mod, meta_model):
        self.mod = mod
        self.meta_model = meta_model  # 元模型
        self.kf = KFold(n_splits=5, random_state=42, shuffle=True)  ##这就是堆叠的最大特征进行了几折的划分

    def fit(self, X, y):
        self.saved_model = [list() for i in self.mod]
        oof_train = np.zeros((X.shape[0], len(self.mod)))

        for i, model in enumerate(self.mod):  # 返回的是索引和模型本身
            for train_index, val_index in self.kf.split(X, y):  ##返回的是数据本省
                renew_model = clone(model)  ##模型的复制
                renew_model.fit(X[train_index], y[train_index])  # 对数据进行训练
                self.saved_model[i].append(renew_model)  ##把模型添加进去
                oof_train[val_index, i] = renew_model.predict(X[val_index])  ##用来预测验证集

        self.meta_model.fit(oof_train, y)  # 元模型
        return self

    def predict(self, X):
        whole_test = np.column_stack([np.column_stack(model.predict(X) for model in single_model).mean(axis=1)
                                      for single_model in self.saved_model])  ##得到的是整个测试集
        return self.meta_model.predict(whole_test)  # 返回的是利用元模型来对整个测试集进行预测

    def get_oof(self, X, y, test_X):
        oof = np.zeros((X.shape[0], len(self.mod)))  ##初始化为0
        test_single = np.zeros((test_X.shape[0], 5))  ##初始化为0
        test_mean = np.zeros((test_X.shape[0], len(self.mod)))
        for i, model in enumerate(self.mod):  ##i是模型
            for j, (train_index, val_index) in enumerate(self.kf.split(X, y)):  ##j是所有划分好的的数据
                clone_model = clone(model)  ##克隆模块，相当于把模型复制一下
                clone_model.fit(X[train_index], y[train_index])  ##把分割好的数据进行训练
                oof[val_index, i] = clone_model.predict(X[val_index])  ##对验证集进行预测
                test_single[:, j] = clone_model.predict(test_X)  ##对测试集进行预测
            test_mean[:, i] = test_single.mean(axis=1)  ##测试集算好均值
        return oof, test_mean

##经过预处理之后才能放到堆叠的模型里面去计算
a = Imputer().fit_transform(X_scaled)#相当于x
b = Imputer().fit_transform(y_log.values.reshape(-1,1)).ravel()#相当于y
stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)#定义了第一层的和第二层的模型
print(rmse_cv(stack_model,a,b))##运用了评估函数
print(rmse_cv(stack_model,a,b).mean())

X_train_stack, X_test_stack = stack_model.get_oof(a,b,test_X_scaled)#将数据进行变换
print(X_train_stack.shape)
print(X_test_stack.shape)

X_train_add = np.hstack((a,X_train_stack))
X_test_add = np.hstack((test_X_scaled,X_test_stack))
print(X_train_add.shape)
print(X_test_add.shape)

print(rmse_cv(stack_model,X_train_add,b))
print(rmse_cv(stack_model,X_train_add,b).mean())

stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)
stack_model.fit(a,b)#模型进行训练
pred = np.exp(stack_model.predict(test_X_scaled))#进行预测
result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred})
result.to_csv("submission_stacking.csv",index=False)
